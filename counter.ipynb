{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from definitions import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from dataset_preparations import get_img_paths, get_labels\n",
    "\n",
    "stanford_training_paths = get_img_paths(STANFORD_TRAIN_PATH)\n",
    "training_labels = get_labels(STANFORD_SET_PATH, \"anno_train.csv\")\n",
    "\n",
    "stanford_validation_paths = get_img_paths(STANFORD_VALIDATION_PATH)\n",
    "validation_labels = get_labels(STANFORD_SET_PATH, \"anno_test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from dataset_preparations import get_dataset\n",
    "\n",
    "training_dataset = get_dataset(stanford_training_paths, training_labels)\n",
    "validation_dataset = get_dataset(stanford_validation_paths, validation_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dataset_preparations import create_data_loader\n",
    "\n",
    "training_data_loader = create_data_loader(training_dataset, True)\n",
    "validation_data_loader = create_data_loader(validation_dataset, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/clinux/faculdade/processamento-imagens-biomedicas/env/lib64/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/mnt/clinux/faculdade/processamento-imagens-biomedicas/env/lib64/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from dataset_preparations import create_model\n",
    "\n",
    "model = create_model(NUM_CLASSES)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = torch.device('cuda')\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from classes import Averager\n",
    "\n",
    "train_itr = 1\n",
    "val_itr = 1\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "train_loss_avg = Averager()\n",
    "val_loss_avg = Averager()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# function for running training iterations\n",
    "def train(train_data_loader, model):\n",
    "    print('Training')\n",
    "    global train_itr\n",
    "    global train_loss_list\n",
    "\n",
    "     # initialize tqdm progress bar\n",
    "    prog_bar = tqdm(train_data_loader, total=len(train_data_loader))\n",
    "\n",
    "    for i, data in enumerate(prog_bar):\n",
    "        optimizer.zero_grad()\n",
    "        images, targets = data\n",
    "\n",
    "        images = list(image.to(DEVICE) for image in images)\n",
    "        # targets = [[i.to(DEVICE) for i in t] for t in targets]\n",
    "        print(targets)\n",
    "        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "        # targets = {k: v.to(DEVICE) for k, v in targets.items()}\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "        train_loss_list.append(loss_value)\n",
    "        train_loss_avg.send(loss_value)\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        train_itr += 1\n",
    "\n",
    "        # update the loss value beside the progress bar for each iteration\n",
    "        prog_bar.set_description(desc=f\"Loss: {loss_value:.4f}\")\n",
    "    return train_loss_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# function for running validation iterations\n",
    "def validate(valid_data_loader, model):\n",
    "    print('Validating')\n",
    "    global val_itr\n",
    "    global val_loss_list\n",
    "\n",
    "    # initialize tqdm progress bar\n",
    "    prog_bar = tqdm(valid_data_loader, total=len(valid_data_loader))\n",
    "\n",
    "    for i, data in enumerate(prog_bar):\n",
    "        images, targets = data\n",
    "\n",
    "        images = list(image.to(DEVICE) for image in images)\n",
    "        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "        val_loss_list.append(loss_value)\n",
    "        val_loss_avg.send(loss_value)\n",
    "        val_itr += 1\n",
    "        # update the loss value beside the progress bar for each iteration\n",
    "        prog_bar.set_description(desc=f\"Loss: {loss_value:.4f}\")\n",
    "    return val_loss_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1 of 10\n",
      "Training\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1018 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc338f1c138048bf8cae889dd0f381cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Expected y_min for bbox (tensor(0.0641), tensor(1.2651), tensor(0.0547), tensor(0.5616), tensor(50)) to be in the range [0.0, 1.0], got 1.265135645866394.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 12\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# start timer and carry out training and validation\u001B[39;00m\n\u001B[1;32m     11\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m---> 12\u001B[0m train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining_data_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m val_loss \u001B[38;5;241m=\u001B[39m validate(validation_data_loader, model)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch #\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m train loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_loss_avg\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[8], line 12\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(train_data_loader, model)\u001B[0m\n\u001B[1;32m      9\u001B[0m  \u001B[38;5;66;03m# initialize tqdm progress bar\u001B[39;00m\n\u001B[1;32m     10\u001B[0m prog_bar \u001B[38;5;241m=\u001B[39m tqdm(train_data_loader, total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(train_data_loader))\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(prog_bar):\n\u001B[1;32m     13\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     14\u001B[0m     images, targets \u001B[38;5;241m=\u001B[39m data\n",
      "File \u001B[0;32m/mnt/clinux/faculdade/processamento-imagens-biomedicas/env/lib64/python3.10/site-packages/tqdm/notebook.py:259\u001B[0m, in \u001B[0;36mtqdm_notebook.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    257\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    258\u001B[0m     it \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m(tqdm_notebook, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__iter__\u001B[39m()\n\u001B[0;32m--> 259\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;66;03m# return super(tqdm...) will not catch exception\u001B[39;00m\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m    262\u001B[0m \u001B[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001B[39;00m\n",
      "File \u001B[0;32m/mnt/clinux/faculdade/processamento-imagens-biomedicas/env/lib64/python3.10/site-packages/tqdm/std.py:1195\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1192\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1195\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1196\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1197\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1198\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m/mnt/clinux/faculdade/processamento-imagens-biomedicas/env/lib64/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m/mnt/clinux/faculdade/processamento-imagens-biomedicas/env/lib64/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    669\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    670\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 671\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    672\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    673\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m/mnt/clinux/faculdade/processamento-imagens-biomedicas/env/lib64/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m/mnt/clinux/faculdade/processamento-imagens-biomedicas/env/lib64/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     56\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m/mnt/clinux/faculdade/Visao Computacional/TAFINAL/classes.py:75\u001B[0m, in \u001B[0;36mImgDataset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     72\u001B[0m image_id \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([idx])\n\u001B[1;32m     73\u001B[0m target \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mboxes\u001B[39m\u001B[38;5;124m\"\u001B[39m: boxes, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m: labels, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: image_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marea\u001B[39m\u001B[38;5;124m\"\u001B[39m: area, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miscrowd\u001B[39m\u001B[38;5;124m\"\u001B[39m: iscrowd}\n\u001B[0;32m---> 75\u001B[0m sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransforms\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimage_resized\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbboxes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mboxes\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m image_resized \u001B[38;5;241m=\u001B[39m sample[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     77\u001B[0m target[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mboxes\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor(sample[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mboxes\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m/mnt/clinux/faculdade/processamento-imagens-biomedicas/env/lib64/python3.10/site-packages/albumentations/core/composition.py:207\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[0;34m(self, force_apply, *args, **data)\u001B[0m\n\u001B[1;32m    202\u001B[0m check_each_transform \u001B[38;5;241m=\u001B[39m \u001B[38;5;28many\u001B[39m(\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;28mgetattr\u001B[39m(item\u001B[38;5;241m.\u001B[39mparams, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcheck_each_transform\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessors\u001B[38;5;241m.\u001B[39mvalues()\n\u001B[1;32m    204\u001B[0m )\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessors\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m--> 207\u001B[0m     \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    209\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(transforms):\n\u001B[1;32m    210\u001B[0m     data \u001B[38;5;241m=\u001B[39m t(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdata)\n",
      "File \u001B[0;32m/mnt/clinux/faculdade/processamento-imagens-biomedicas/env/lib64/python3.10/site-packages/albumentations/core/utils.py:83\u001B[0m, in \u001B[0;36mDataProcessor.preprocess\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     81\u001B[0m rows, cols \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[:\u001B[38;5;241m2\u001B[39m]\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data_name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_fields:\n\u001B[0;32m---> 83\u001B[0m     data[data_name] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_and_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdata_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcols\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdirection\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mto\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/mnt/clinux/faculdade/processamento-imagens-biomedicas/env/lib64/python3.10/site-packages/albumentations/core/utils.py:91\u001B[0m, in \u001B[0;36mDataProcessor.check_and_convert\u001B[0;34m(self, data, rows, cols, direction)\u001B[0m\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m data\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m direction \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 91\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_albumentations\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m direction \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvert_from_albumentations(data, rows, cols)\n",
      "File \u001B[0;32m/mnt/clinux/faculdade/processamento-imagens-biomedicas/env/lib64/python3.10/site-packages/albumentations/core/bbox_utils.py:142\u001B[0m, in \u001B[0;36mBboxProcessor.convert_to_albumentations\u001B[0;34m(self, data, rows, cols)\u001B[0m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconvert_to_albumentations\u001B[39m(\u001B[38;5;28mself\u001B[39m, data: Sequence[BoxType], rows: \u001B[38;5;28mint\u001B[39m, cols: \u001B[38;5;28mint\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[BoxType]:\n\u001B[0;32m--> 142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconvert_bboxes_to_albumentations\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcols\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_validity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/mnt/clinux/faculdade/processamento-imagens-biomedicas/env/lib64/python3.10/site-packages/albumentations/core/bbox_utils.py:408\u001B[0m, in \u001B[0;36mconvert_bboxes_to_albumentations\u001B[0;34m(bboxes, source_format, rows, cols, check_validity)\u001B[0m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconvert_bboxes_to_albumentations\u001B[39m(\n\u001B[1;32m    405\u001B[0m     bboxes: Sequence[BoxType], source_format, rows, cols, check_validity\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    406\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[BoxType]:\n\u001B[1;32m    407\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Convert a list bounding boxes from a format specified in `source_format` to the format used by albumentations\"\"\"\u001B[39;00m\n\u001B[0;32m--> 408\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [convert_bbox_to_albumentations(bbox, source_format, rows, cols, check_validity) \u001B[38;5;28;01mfor\u001B[39;00m bbox \u001B[38;5;129;01min\u001B[39;00m bboxes]\n",
      "File \u001B[0;32m/mnt/clinux/faculdade/processamento-imagens-biomedicas/env/lib64/python3.10/site-packages/albumentations/core/bbox_utils.py:408\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconvert_bboxes_to_albumentations\u001B[39m(\n\u001B[1;32m    405\u001B[0m     bboxes: Sequence[BoxType], source_format, rows, cols, check_validity\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    406\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[BoxType]:\n\u001B[1;32m    407\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Convert a list bounding boxes from a format specified in `source_format` to the format used by albumentations\"\"\"\u001B[39;00m\n\u001B[0;32m--> 408\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mconvert_bbox_to_albumentations\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbbox\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msource_format\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcols\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_validity\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m bbox \u001B[38;5;129;01min\u001B[39;00m bboxes]\n",
      "File \u001B[0;32m/mnt/clinux/faculdade/processamento-imagens-biomedicas/env/lib64/python3.10/site-packages/albumentations/core/bbox_utils.py:352\u001B[0m, in \u001B[0;36mconvert_bbox_to_albumentations\u001B[0;34m(bbox, source_format, rows, cols, check_validity)\u001B[0m\n\u001B[1;32m    350\u001B[0m     bbox \u001B[38;5;241m=\u001B[39m normalize_bbox(bbox, rows, cols)\n\u001B[1;32m    351\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_validity:\n\u001B[0;32m--> 352\u001B[0m     \u001B[43mcheck_bbox\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbbox\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m bbox\n",
      "File \u001B[0;32m/mnt/clinux/faculdade/processamento-imagens-biomedicas/env/lib64/python3.10/site-packages/albumentations/core/bbox_utils.py:435\u001B[0m, in \u001B[0;36mcheck_bbox\u001B[0;34m(bbox)\u001B[0m\n\u001B[1;32m    433\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, value \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx_min\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_min\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx_max\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_max\u001B[39m\u001B[38;5;124m\"\u001B[39m], bbox[:\u001B[38;5;241m4\u001B[39m]):\n\u001B[1;32m    434\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m value \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misclose(value, \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misclose(value, \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m--> 435\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for bbox \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbbox\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m to be in the range [0.0, 1.0], got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    436\u001B[0m x_min, y_min, x_max, y_max \u001B[38;5;241m=\u001B[39m bbox[:\u001B[38;5;241m4\u001B[39m]\n\u001B[1;32m    437\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x_max \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m x_min:\n",
      "\u001B[0;31mValueError\u001B[0m: Expected y_min for bbox (tensor(0.0641), tensor(1.2651), tensor(0.0547), tensor(0.5616), tensor(50)) to be in the range [0.0, 1.0], got 1.265135645866394."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "NUM_EPOCHS = 10 # number of epochs to train for\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEPOCH {epoch+1} of {NUM_EPOCHS}\")\n",
    "\n",
    "    # reset the training and validation loss histories for the current epoch\n",
    "    train_loss_avg.reset()\n",
    "    val_loss_avg.reset()\n",
    "    # start timer and carry out training and validation\n",
    "    start = time.time()\n",
    "    train_loss = train(training_data_loader, model)\n",
    "    val_loss = validate(validation_data_loader, model)\n",
    "    print(f\"Epoch #{epoch+1} train loss: {train_loss_avg.value:.3f}\")\n",
    "    print(f\"Epoch #{epoch+1} validation loss: {val_loss_avg.value:.3f}\")\n",
    "    end = time.time()\n",
    "    print(f\"Took {((end - start) / 60):.3f} minutes for epoch {epoch}\")\n",
    "    # save the best model till now if we have the least loss in the...\n",
    "    # ... current epoch\n",
    "    # save_best_model(\n",
    "    #     train_loss_avg.value, epoch, model, optimizer\n",
    "    # )\n",
    "    # save the current epoch model\n",
    "    # save_model(epoch, model, optimizer)\n",
    "    # save loss plot\n",
    "    # save_loss_plot(OUT_DIR, train_loss, val_loss)\n",
    "\n",
    "    # sleep for 5 seconds after each epoch\n",
    "    time.sleep(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}